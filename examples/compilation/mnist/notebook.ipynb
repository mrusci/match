{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb9d3eec",
   "metadata": {},
   "source": [
    "# Let's compile a model trained on mnist with MATCH\n",
    "The model can be found in the model directory and has been pre-trained, quantized and integerized with PLiNIO https://github.com/eml-eda/plinio to int32 to target ARCANE.\n",
    "This model is quantized to int8, and is comprised by a set of Dense(MatMul)+BatchNorm(multiply+add) operations, thanks to PLiNIO Dense Weigths and BatchNorm constants are trained to decrease the error, also additionally there is a Div operation, that serves as a rescale factor. \n",
    "In the PLiNIO repository there are examples to reproduce the model directory, where we have our input, the expected label and finally also the model itself.\n",
    "In this case we'll compile the model for the default target where only the host-cpu will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9019517a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First let's import all the required libraries and setup correctly the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup environment variables of MATCH and TVM\n",
    "import os\n",
    "CURR_PATH = \"./\"\n",
    "MATCH_PATH = \"./../../../\"\n",
    "TVM_HOME = f\"{MATCH_PATH}/match-tvm\"\n",
    "os.environ[\"TVM_HOME\"] = TVM_HOME\n",
    "os.environ[\"PYTHONPATH\"] = f\"{TVM_HOME}/python:{MATCH_PATH}/zigzag:{os.environ['PYTHONPATH']}\"\n",
    "# MATCH imports\n",
    "import match\n",
    "from match.target.target import DefaultMatchTarget\n",
    "from match.utils.utils import get_default_inputs\n",
    "from match.model.model import MatchModel\n",
    "from tvm import relay\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbaba6b",
   "metadata": {},
   "source": [
    "## Match Model\n",
    "Now let's define the model in MATCH, these are the parameters used for MatchModel:\n",
    "- filename: ONNX/Relay IR file containing the model definition\n",
    "- model\\_name: name that will be used to identify the model in case of multi-model compilation or more complex situations\n",
    "- default\\_inputs: inputs which will be used to compile the model, they will be stored in src(include)/model\\_name/default_input.c(h), by default the model will run with this inputs if not specified otherwise\n",
    "- handle\\_out\\_fn: function used to handle the output after a single inference(with the default inputs), in this case we'll use a MATCH-provided one that handle int32 classification, but a user-specified one can be put\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de0e47",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = CURR_PATH+\"/model/input.txt\"\n",
    "onnx_file_path = CURR_PATH+\"/model/mnist.onnx\"\n",
    "onnx_model = onnx.load(onnx_file_path)\n",
    "mod, _ = relay.frontend.from_onnx(onnx_model)\n",
    "mnist_model = MatchModel(\n",
    "    filename=onnx_file_path,\n",
    "    model_name=\"mnist\",\n",
    "    default_inputs=get_default_inputs(mod=mod, input_files=[input_file]),\n",
    "    handle_out_fn=\"handle_int_classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3401d310",
   "metadata": {},
   "source": [
    "## Compile the MatchModel\n",
    "Finally with the MatchModel available we can compile it with MATCH for the provided target!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e149973",
   "metadata": {},
   "outputs": [],
   "source": [
    "match.match(\n",
    "    model=mnist_model,\n",
    "    target=DefaultMatchTarget(),\n",
    "    output_path=CURR_PATH+\"/output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230dca3b",
   "metadata": {},
   "source": [
    "## Compilation result\n",
    "Now we can check the graph of the network in Relay IR(TVM lower level IR to represent a network).\n",
    "After we can compile it to binary and run it to check if we obtain the expected result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c1b6f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!cat output/models/mnist/relay/partitioned_graph.relay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434bea7",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!cd output; make all; ./match_app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32810d47",
   "metadata": {},
   "source": [
    "The expected label should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d8c7d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!cat model/label.txt"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
